{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.error import URLError\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import pymysql\n",
    "import ssl\n",
    "from pymysql import Error\n",
    "\n",
    "def decode_page(page_bytes, charsets=('utf-8',)):\n",
    "    page_html = None\n",
    "    for charset in charsets:\n",
    "        try:\n",
    "            page_html = page_bytes.decode(charset)\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            print('UnicodeDecodeError')\n",
    "            pass\n",
    "    return page_html\n",
    "\n",
    "\n",
    "def get_page_html(seed_url, *, retry_times=3, charsets=('utf-8',)):\n",
    "    page_html = None\n",
    "    try:\n",
    "        page_html = decode_page(urlopen(seed_url).read(), charsets)\n",
    "    except URLError:\n",
    "        if retry_times > 0:\n",
    "            return get_page_html(seed_url, retry_times=retry_times - 1, charsets=charsets)\n",
    "    except:\n",
    "        print('aooooo')\n",
    "    return page_html\n",
    "\n",
    "def get_matched_parts(page_html, pattern_str, pattern_ignore_case=re.I):\n",
    "    pattern_regex = re.compile(pattern_str, pattern_ignore_case)\n",
    "    return pattern_regex.findall(page_html) if page_html else []\n",
    "\n",
    "def start_crawl(seed_url, match_pattern, *, max_depth=-1):\n",
    "    conn = pymysql.connect(\n",
    "        host='127.0.0.1', \n",
    "        port=3306, \n",
    "        database='d1', \n",
    "        charset='utf8', \n",
    "        user='root', \n",
    "        password='2313'\n",
    "    )\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            url_list = [seed_url]\n",
    "            visited_url_list = {seed_url: 0}\n",
    "            while url_list:\n",
    "                current_url = url_list.pop(0)\n",
    "                depth = visited_url_list[current_url]\n",
    "                if depth != max_depth:\n",
    "                    # 用'utf-8', 'gbk', 'gb2312'三种字符集解码网页\n",
    "                    page_html = get_page_html(current_url, charsets=('utf-8', 'gbk', 'gb2312'))\n",
    "#                     print(page_html)\n",
    "                    # 匹配出网页中的链接\n",
    "#                     links_list = get_matched_parts(page_html, match_pattern)\n",
    "#                     param_list = []\n",
    "#                     for link in links_list:\n",
    "#                         if link not in visited_url_list:\n",
    "#                             visited_url_list[link] = depth + 1\n",
    "#                             page_html = get_page_html(link, charsets=('utf-8', 'gbk', 'gb2312'))\n",
    "#                             headings = get_matched_parts(page_html, r'<h1>(.*)<span')\n",
    "#                             if headings:\n",
    "#                                 param_list.append((headings[0], link))\n",
    "#                     cursor.executemany('insert into tb_result (title, link) values (%s, %s)', params_list)\n",
    "#                     conn.commit()\n",
    "    except Error:\n",
    "        print('Error')\n",
    "        pass\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def main():\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    start_crawl('http://sports.sohu.com.nba_a.shtml', r'<a[^>]+test=a\\s[^>]*href=[\"\\'](.*?)[\"\\']', max_depth=2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop database if exists d1;\n",
    "create database d1 default charset utf8;\n",
    "\n",
    "use tb_result;\n",
    "\n",
    "drop table if exists tb_result;\n",
    "\n",
    "create table tb_result\n",
    "(\n",
    "id   int not null auto_increment comment 'id',\n",
    "title varchar(50) not null comment '标题',\n",
    "link  varchar(50) not null comment '链接',\n",
    "primary key (id)\n",
    ");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
